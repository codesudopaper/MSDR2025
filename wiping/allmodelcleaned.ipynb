{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset, implement the models (same as your script), train BC / Traj-BC / BC-RNN / ILEED,\n",
    "# and compute each model's training loss (no rollouts). Results will be shown in a table and saved to CSV.\n",
    "\n",
    "import numpy as np\n",
    "import math, time, json, os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from caas_jupyter_tools import display_dataframe_to_user\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Load the attached dataset ----------------\n",
    "path = \"./cleaned_dataset.npy\"\n",
    "arr = np.load(path)\n",
    "assert arr.ndim == 3 and arr.shape == (4, 300, 4), f\"Expected (4,300,4), got {arr.shape}\"\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "for i in range(arr.shape[0]):   # loop over trajectories\n",
    "    traj = arr[i]  # shape: (300, 4)\n",
    "    \n",
    "    state1 = traj[:, 0]  # first state\n",
    "    state2 = traj[:, 1]  # second state\n",
    "    \n",
    "    plt.plot(\n",
    "        state1, state2,\n",
    "        linewidth=2.5,   # bold trajectories\n",
    "        label=f\"Trajectory {i+1}\"\n",
    "    )\n",
    "\n",
    "# Bold title\n",
    "# plt.title(\"Clean Trajectories weaving\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# Bold axis labels\n",
    "# plt.xlabel(\"X axis\", fontsize=12, fontweight=\"bold\")\n",
    "# plt.ylabel(\"Y axis\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "# Bold tick labels\n",
    "plt.xticks(fontsize=16, fontweight=\"bold\")\n",
    "plt.yticks(fontsize=16, fontweight=\"bold\")\n",
    "\n",
    "# Fix axis range to [-2, 2]\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "\n",
    "# Grid and aspect ratio\n",
    "plt.grid(True, linewidth=1.2)\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "# Bold legend\n",
    "# plt.legend(fontsize=10, frameon=True)\n",
    "\n",
    "# Save high-resolution image\n",
    "plt.savefig(\"Cleaned_trajectories_hh.png\", dpi=600, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build demos: first 2 columns = states, next 2 = actions\n",
    "demos = []\n",
    "for i in range(arr.shape[0]):\n",
    "    S = arr[i,:, :2].astype(np.float32)\n",
    "    A = arr[i,:, 2:4].astype(np.float32)\n",
    "    demos.append({\"states\": S, \"actions_exec\": A})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "Xs, Ys, Ids = [], [], []\n",
    "off = 0\n",
    "for i, d in enumerate(demos):\n",
    "    S = d[\"states\"]; A = d[\"actions_exec\"]\n",
    "    Xs.append(S); Ys.append(A)\n",
    "    Ids.append(np.full((S.shape[0],), i, np.int64))\n",
    "X = np.concatenate(Xs, axis=0)\n",
    "Y = np.concatenate(Ys, axis=0)\n",
    "demo_ids = np.concatenate(Ids, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize\n",
    "def normalize_xy(X, Y):\n",
    "    x_mean, x_std = X.mean(0), X.std(0) + 1e-6\n",
    "    y_mean, y_std = Y.mean(0), Y.std(0) + 1e-6\n",
    "    Xn = (X - x_mean) / x_std\n",
    "    Yn = (Y - y_mean) / y_std\n",
    "    stats = dict(x_mean=x_mean, x_std=x_std, y_mean=y_mean, y_std=y_std)\n",
    "    return Xn, Yn, stats\n",
    "\n",
    "Xn, Yn, stats = normalize_xy(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch(*arrs, device=\"cpu\"):\n",
    "    out=[]\n",
    "    for a in arrs:\n",
    "        if isinstance(a,np.ndarray) and a.dtype==np.int64:\n",
    "            out.append(torch.tensor(a,dtype=torch.long,device=device))\n",
    "        else:\n",
    "            out.append(torch.tensor(a,dtype=torch.float32,device=device))\n",
    "    return out\n",
    "\n",
    "device = \"cpu\"\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- New Models ----------------\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, p, d, width=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(p, width), nn.ReLU(),\n",
    "            nn.Linear(width, width), nn.ReLU(),\n",
    "            nn.Linear(width, d),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class GaussianMLP(nn.Module):\n",
    "    def __init__(self, p, d, width=128, min_std=1e-3):\n",
    "        super().__init__()\n",
    "        self.min_std = min_std\n",
    "        self.mu_head = nn.Sequential(\n",
    "            nn.Linear(p, width), nn.ReLU(),\n",
    "            nn.Linear(width, width), nn.ReLU(),\n",
    "            nn.Linear(width, d)\n",
    "        )\n",
    "        self.log_std_head = nn.Sequential(\n",
    "            nn.Linear(p, width), nn.ReLU(),\n",
    "            nn.Linear(width, width), nn.ReLU(),\n",
    "            nn.Linear(width, d)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        mu = self.mu_head(x)\n",
    "        log_std = self.log_std_head(x)\n",
    "        std = F.softplus(log_std) + self.min_std\n",
    "        return D.Independent(D.Normal(loc=mu, scale=std), 1)\n",
    "\n",
    "class GMMMLP(nn.Module):\n",
    "    def __init__(self, p, d, M=5, width=128, min_std=1e-3):\n",
    "        super().__init__()\n",
    "        self.M = M\n",
    "        self.d = d\n",
    "        self.min_std = min_std\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(p, width), nn.ReLU(),\n",
    "            nn.Linear(width, width), nn.ReLU()\n",
    "        )\n",
    "        self.pi_head = nn.Linear(width, M)\n",
    "        self.mu_head = nn.Linear(width, M * d)\n",
    "        self.log_std_head = nn.Linear(width, M * d)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.net(x)\n",
    "        B = x.shape[0]\n",
    "        pi_logits = self.pi_head(h)\n",
    "        mu = self.mu_head(h).view(B, self.M, self.d)\n",
    "        log_std = self.log_std_head(h).view(B, self.M, self.d)\n",
    "        std = F.softplus(log_std) + self.min_std\n",
    "        \n",
    "        comp_dist = D.Independent(D.Normal(loc=mu, scale=std), 1)\n",
    "        mix_dist = D.Categorical(logits=pi_logits)\n",
    "        return D.MixtureSameFamily(mix_dist, comp_dist)\n",
    "\n",
    "class GRUPolicy(nn.Module):\n",
    "    def __init__(self, p, d, h=128):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(p, h, batch_first=True)\n",
    "        self.head = nn.Linear(h, d)\n",
    "    def forward(self, x, h0=None):\n",
    "        o, h = self.gru(x, h0); y = self.head(o); return y, h\n",
    "\n",
    "class TransformerPolicy(nn.Module):\n",
    "    def __init__(self, p, d, nhead=2, nlayers=2, dim_feedforward=256, dropout=0.1, context_length=32):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.d = d\n",
    "        self.context_length = context_length\n",
    "        self.input_proj = nn.Linear(p, dim_feedforward)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim_feedforward, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=nlayers)\n",
    "        self.output_head = nn.Linear(dim_feedforward, d)\n",
    "    def forward(self, x):\n",
    "        h = self.input_proj(x)\n",
    "        h = self.transformer_encoder(h)\n",
    "        return self.output_head(h)\n",
    "\n",
    "# ----- ILEED (paper-faithful continuous) -----\n",
    "class ILEEDGMM(nn.Module):\n",
    "    def __init__(self, p, d, n_demos, M=5, k=16, width=128, rho_min=0.05,\n",
    "                 l2_omega=1e-3, l2_embed=1e-4, aux_lambda=1e-2):\n",
    "        super().__init__()\n",
    "        self.p, self.d, self.M, self.k = p, d, M, k\n",
    "        self.width = width\n",
    "        self.rho_min = rho_min\n",
    "        self.l2_omega = l2_omega\n",
    "        self.l2_embed = l2_embed\n",
    "        self.aux_lambda = aux_lambda\n",
    "        hid = width\n",
    "        self.feat = nn.Sequential(nn.Linear(p,hid), nn.ReLU(),\n",
    "                                  nn.Linear(hid,hid), nn.ReLU())\n",
    "        self.pi_head   = nn.Linear(hid, M)\n",
    "        self.mu_head   = nn.Linear(hid, M*d)\n",
    "        self.logsig_head = nn.Linear(hid, M*d)\n",
    "        self.embed = nn.Sequential(nn.Linear(p,width), nn.ReLU(), nn.Linear(width,k))\n",
    "        self.omega = nn.Parameter(torch.zeros(n_demos,k))\n",
    "        nn.init.normal_(self.omega, std=0.1)\n",
    "        self.trans = nn.Sequential(\n",
    "            nn.Linear(k + d, width), nn.ReLU(),\n",
    "            nn.Linear(width, width), nn.ReLU(),\n",
    "            nn.Linear(width, k),\n",
    "        )\n",
    "        self.min_sigma = 1e-3\n",
    "    def gmm_params(self, s):\n",
    "        h = self.feat(s)\n",
    "        B = s.shape[0]\n",
    "        pi_logits = self.pi_head(h)\n",
    "        mu = self.mu_head(h).view(B, self.M, self.d)\n",
    "        log_sigma = self.logsig_head(h).view(B, self.M, self.d)\n",
    "        sigma = torch.nn.functional.softplus(log_sigma) + self.min_sigma\n",
    "        return pi_logits, mu, sigma\n",
    "    def rho_from_ids(self, s_for_embed, demo_ids):\n",
    "        z = self.embed(s_for_embed)\n",
    "        w = self.omega[demo_ids]\n",
    "        rho = torch.sigmoid((z*w).sum(-1, keepdim=True))\n",
    "        rho = torch.clamp(rho, min=self.rho_min, max=1.0)\n",
    "        return rho, z\n",
    "    def logprob(self, a, pi_logits, mu, sigma, rho):\n",
    "        B,M,d = a.shape[0], self.M, self.d\n",
    "        a_exp = a[:,None,:].expand(B,M,d)\n",
    "        quad_base = ((a_exp - mu) / (sigma+1e-8))**2\n",
    "        quad_base = quad_base.sum(-1)\n",
    "        s2log = (2.0*torch.log(sigma+1e-8)).sum(-1)\n",
    "        logdet_eff = s2log - d * torch.log(rho+1e-8)\n",
    "        const = d * math.log(2*math.pi)\n",
    "        logN = -0.5*(const + logdet_eff + rho*quad_base)\n",
    "        logpi = torch.log_softmax(pi_logits, dim=-1)\n",
    "        logmix = logpi + logN\n",
    "        return torch.logsumexp(logmix, dim=-1)\n",
    "    def nll_with_aux(self, s_policy, s_embed, a, demo_ids, s_next, aux_lambda=None):\n",
    "        pi_logits, mu, sigma = self.gmm_params(s_policy)\n",
    "        rho, z = self.rho_from_ids(s_embed, demo_ids)\n",
    "        logp = self.logprob(a, pi_logits, mu, sigma, rho)\n",
    "        nll = -logp.mean()\n",
    "        if aux_lambda is None:\n",
    "            aux_lambda = self.aux_lambda\n",
    "        with torch.no_grad():\n",
    "            z_next_target = self.embed(s_next)\n",
    "        z_pred = self.trans(torch.cat([z, a], dim=-1))\n",
    "        aux = ((z_pred - z_next_target)**2).mean()\n",
    "        reg = self.l2_omega*(self.omega**2).mean() + self.l2_embed*(z**2).mean()\n",
    "        return nll + aux_lambda*aux + reg, dict(nll=nll.detach(), aux=aux.detach(), reg=reg.detach())\n",
    "    \n",
    "class ODEFunc(nn.Module):\n",
    "    def __init__(self, p, d, width=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(p, width), nn.ReLU(),\n",
    "            nn.Linear(width, width), nn.ReLU(),\n",
    "            nn.Linear(width, p),  # Output is the derivative of the state\n",
    "        )\n",
    "    def forward(self, t, x):\n",
    "        # The ODE solver requires `t` as an argument, but we don't use it for time-invariant dynamics.\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Helpers for datasets ----------------\n",
    "def make_seq_dataset(demos, Xn, Yn, seq_len=32, seq_stride=16):\n",
    "    seqs=[]; off=0\n",
    "    for d in demos:\n",
    "        T=d[\"states\"].shape[0]\n",
    "        xs=Xn[off:off+T]; ys=Yn[off:off+T]; off+=T\n",
    "        for s in range(0, max(1,T-seq_len+1), seq_stride):\n",
    "            e=min(T,s+seq_len); seqs.append((xs[s:e], ys[s:e]))\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transition_dataset(demos, Xn, Yn):\n",
    "    S=[]; A=[]; S2=[]; ids=[]\n",
    "    off=0\n",
    "    for i,d in enumerate(demos):\n",
    "        T=d[\"states\"].shape[0]\n",
    "        if T<2: off+=T; continue\n",
    "        S.append(Xn[off:off+T-1])\n",
    "        A.append(Yn[off:off+T-1])\n",
    "        S2.append(Xn[off+1:off+T])\n",
    "        ids.append(np.full((T-1,), i, np.int64))\n",
    "        off+=T\n",
    "    if len(S)==0:\n",
    "        return np.zeros((0,Xn.shape[1]),np.float32), np.zeros((0,Yn.shape[1]),np.float32), np.zeros((0,Xn.shape[1]),np.float32), np.zeros((0,),np.int64)\n",
    "    return np.concatenate(S,0), np.concatenate(A,0), np.concatenate(S2,0), np.concatenate(ids,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Training functions (same loss definitions) ----------------\n",
    "def train_bc(Xn, Yn, width=128, W=None, lr=1e-3, epochs=120, batch=8192, device=\"cpu\", clip=1.0):\n",
    "    p,d = Xn.shape[1], Yn.shape[1]\n",
    "    net = MLP(p,d,width=width).to(device)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    Xt,Yt = to_torch(Xn,Yn,device=device)\n",
    "    Wt = torch.ones(Xt.shape[0],device=device) if W is None else torch.tensor(W,dtype=torch.float32,device=device)\n",
    "    N=Xt.shape[0]; B=min(batch,N)\n",
    "    for _ in range(epochs):\n",
    "        idx=torch.randperm(N,device=device)\n",
    "        for k in range(0,N,B):\n",
    "            sel=idx[k:k+B]; x=Xt[sel]; y=Yt[sel]; w=Wt[sel]\n",
    "            pred=net(x); mse=((pred-y)**2).sum(-1); loss=(w*mse).mean()\n",
    "            opt.zero_grad(); loss.backward()\n",
    "            if clip: nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "    # final training loss (same objective)\n",
    "    with torch.no_grad():\n",
    "        pred = net(Xt); mse = ((pred - Yt)**2).sum(-1)\n",
    "        loss = (Wt * mse).mean().item()\n",
    "    return net, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(demos, Xn, Yn, hidden=128, seq_len=32, seq_stride=16, lr=1e-3, epochs=120, batch=64, device=\"cpu\", clip=1.0):\n",
    "    p,d=Xn.shape[1], Yn.shape[1]\n",
    "    net=GRUPolicy(p,d,h=hidden).to(device)\n",
    "    opt=optim.Adam(net.parameters(), lr=lr)\n",
    "    seqs=make_seq_dataset(demos, Xn, Yn, seq_len, seq_stride)\n",
    "    for _ in range(epochs):\n",
    "        np.random.shuffle(seqs)\n",
    "        for i in range(0,len(seqs),batch):\n",
    "            bs=seqs[i:i+batch]; maxT=max(s[0].shape[0] for s in bs)\n",
    "            xpad=np.zeros((len(bs),maxT,p),np.float32)\n",
    "            ypad=np.zeros((len(bs),maxT,d),np.float32)\n",
    "            mask=np.zeros((len(bs),maxT),np.float32)\n",
    "            for b,(sx,sy) in enumerate(bs):\n",
    "                T=sx.shape[0]; xpad[b,:T]=sx; ypad[b,:T]=sy; mask[b,:T]=1.0\n",
    "            xt,yt,mt = to_torch(xpad,ypad,mask,device=device)\n",
    "            pred,_=net(xt); mse=((pred-yt)**2).sum(-1)\n",
    "            loss=(mse*mt).sum()/(mt.sum()+1e-8)\n",
    "            opt.zero_grad(); loss.backward()\n",
    "            if clip: nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "    # final training loss (same masked MSE objective) computed over the same seq dataset\n",
    "    with torch.no_grad():\n",
    "        total_num = 0.0\n",
    "        total_den = 0.0\n",
    "        for i in range(0,len(seqs),batch):\n",
    "            bs=seqs[i:i+batch]; maxT=max(s[0].shape[0] for s in bs)\n",
    "            xpad=np.zeros((len(bs),maxT,p),np.float32)\n",
    "            ypad=np.zeros((len(bs),maxT,d),np.float32)\n",
    "            mask=np.zeros((len(bs),maxT),np.float32)\n",
    "            for b,(sx,sy) in enumerate(bs):\n",
    "                T=sx.shape[0]; xpad[b,:T]=sx; ypad[b,:T]=sy; mask[b,:T]=1.0\n",
    "            xt,yt,mt = to_torch(xpad,ypad,mask,device=device)\n",
    "            pred,_=net(xt); mse=((pred-yt)**2).sum(-1)\n",
    "            total_num += (mse*mt).sum().item()\n",
    "            total_den += mt.sum().item()\n",
    "        loss = total_num / max(1e-8, total_den)\n",
    "    return net, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_traj_bc(demos, Xn, Yn, width=128, lr=1e-3, epochs=120, batch=8192, device=\"cpu\", clip=1.0):\n",
    "    # per-trajectory weights (same heuristic)\n",
    "    demo_w=[]\n",
    "    for d in demos:\n",
    "        slip_frac=float(d.get(\"slip_width\", 0.25))\n",
    "        clip_ratio=float(d.get(\"clip_ratio\", 0.05))\n",
    "        dist=float(d.get(\"distance\", 8.0))\n",
    "        w=(1.0 - 0.5*slip_frac) * (1.0 - 0.3*clip_ratio) * (1.0 + 0.02*dist)\n",
    "        demo_w.append(w)\n",
    "    demo_w=np.array(demo_w,np.float32); demo_w/=demo_w.mean()\n",
    "    W=np.concatenate([np.full(d[\"states\"].shape[0], w, np.float32) for w,d in zip(demo_w, demos)],0)\n",
    "    net, loss = train_bc(Xn, Yn, width=width, W=W, lr=lr, epochs=epochs, batch=batch, device=device, clip=clip)\n",
    "    return net, loss, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ileed_paperfaithful(demos, Xn, Yn, demo_ids, width=128, k=16, M=5, rho_min=0.05,\n",
    "                              l2_omega=1e-3, l2_embed=1e-4, aux_lambda=1e-2,\n",
    "                              epochs_warm=60, epochs_joint=90, lr_warm=1e-3, lr_joint=6e-4,\n",
    "                              batch=256, grad_clip=1.0, device=\"cpu\"):\n",
    "    p, d = Xn.shape[1], Yn.shape[1]; n_d = len(demos)\n",
    "    net = ILEEDGMM(p, d, n_d, M=M, k=k, width=width, rho_min=rho_min,\n",
    "                   l2_omega=l2_omega, l2_embed=l2_embed, aux_lambda=aux_lambda).to(device)\n",
    "    S0, A0, S1, ids_tr = make_transition_dataset(demos, Xn, Yn)\n",
    "    Xt, At, Xnext, Ids_tr = to_torch(S0, A0, S1, ids_tr, device=device)\n",
    "    Ntr = Xt.shape[0]; B = min(batch, Ntr)\n",
    "    # Warm\n",
    "    Xall, Yall = to_torch(Xn, Yn, device=device)\n",
    "    Nall = Xall.shape[0]; Bw = min(batch, Nall)\n",
    "    freezed = list(net.embed.parameters()) + [net.omega] + list(net.trans.parameters())\n",
    "    for pmt in freezed: pmt.requires_grad_(False)\n",
    "    opt_warm = optim.Adam(\n",
    "        list(net.feat.parameters()) + list(net.pi_head.parameters())\n",
    "        + list(net.mu_head.parameters()) + list(net.logsig_head.parameters()),\n",
    "        lr=lr_warm\n",
    "    )\n",
    "    for _ in range(epochs_warm):\n",
    "        idx = torch.randperm(Nall, device=device)\n",
    "        for k0 in range(0, Nall, Bw):\n",
    "            sel = idx[k0:k0+Bw]\n",
    "            pi_logits, mu, sigma = net.gmm_params(Xall[sel])\n",
    "            rho_ones = torch.ones((sel.shape[0],1), device=device)\n",
    "            logp = net.logprob(Yall[sel], pi_logits, mu, sigma, rho_ones)\n",
    "            loss = -logp.mean()\n",
    "            opt_warm.zero_grad(); loss.backward()\n",
    "            if grad_clip: nn.utils.clip_grad_norm_(net.parameters(), grad_clip)\n",
    "            opt_warm.step()\n",
    "    # Joint\n",
    "    for pmt in freezed: pmt.requires_grad_(True)\n",
    "    opt_joint = optim.Adam(net.parameters(), lr=lr_joint)\n",
    "    for _ in range(epochs_joint):\n",
    "        idx = torch.randperm(Ntr, device=device)\n",
    "        for k0 in range(0, Ntr, B):\n",
    "            sel = idx[k0:k0+B]\n",
    "            loss, _logs = net.nll_with_aux(\n",
    "                s_policy= Xt[sel],\n",
    "                s_embed = Xt[sel],\n",
    "                a       = At[sel],\n",
    "                demo_ids= Ids_tr[sel],\n",
    "                s_next  = Xnext[sel]\n",
    "            )\n",
    "            opt_joint.zero_grad(); loss.backward()\n",
    "            if grad_clip: nn.utils.clip_grad_norm_(net.parameters(), grad_clip)\n",
    "            opt_joint.step()\n",
    "    # Final training loss on transitions (same objective)\n",
    "    with torch.no_grad():\n",
    "        loss, logs = net.nll_with_aux(s_policy=Xt, s_embed=Xt, a=At, demo_ids=Ids_tr, s_next=Xnext)\n",
    "        loss_val = float(loss.item())\n",
    "        components = {k: float(v.item()) for k,v in logs.items()}\n",
    "    return net, loss_val, components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- New Training Functions ----------------\n",
    "\n",
    "def train_bc_gaussian(Xn, Yn, width=128, lr=1e-3, epochs=120, batch=8192, device=\"cpu\", clip=1.0):\n",
    "    p, d = Xn.shape[1], Yn.shape[1]\n",
    "    net = GaussianMLP(p, d, width=width).to(device)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    Xt, Yt = to_torch(Xn, Yn, device=device)\n",
    "    N = Xt.shape[0]; B = min(batch, N)\n",
    "    for _ in range(epochs):\n",
    "        idx = torch.randperm(N, device=device)\n",
    "        for k in range(0, N, B):\n",
    "            sel = idx[k:k+B]; x = Xt[sel]; y = Yt[sel]\n",
    "            dist = net(x)\n",
    "            loss = -dist.log_prob(y).mean()\n",
    "            opt.zero_grad(); loss.backward()\n",
    "            if clip: nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "    with torch.no_grad():\n",
    "        dist = net(Xt)\n",
    "        loss = -dist.log_prob(Yt).mean().item()\n",
    "    return net, loss\n",
    "\n",
    "def train_bc_gmm(Xn, Yn, width=128, M=5, lr=1e-3, epochs=120, batch=8192, device=\"cpu\", clip=1.0):\n",
    "    p, d = Xn.shape[1], Yn.shape[1]\n",
    "    net = GMMMLP(p, d, M=M, width=width).to(device)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    Xt, Yt = to_torch(Xn, Yn, device=device)\n",
    "    N = Xt.shape[0]; B = min(batch, N)\n",
    "    for _ in range(epochs):\n",
    "        idx = torch.randperm(N, device=device)\n",
    "        for k in range(0, N, B):\n",
    "            sel = idx[k:k+B]; x = Xt[sel]; y = Yt[sel]\n",
    "            dist = net(x)\n",
    "            loss = -dist.log_prob(y).mean()\n",
    "            opt.zero_grad(); loss.backward()\n",
    "            if clip: nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "    with torch.no_grad():\n",
    "        dist = net(Xt)\n",
    "        loss = -dist.log_prob(Yt).mean().item()\n",
    "    return net, loss\n",
    "\n",
    "def train_bc_transformer(demos, Xn, Yn, width=256, nhead=2, nlayers=2, seq_len=32, seq_stride=16, lr=1e-3, epochs=120, batch=64, device=\"cpu\", clip=1.0):\n",
    "    p, d = Xn.shape[1], Yn.shape[1]\n",
    "    net = TransformerPolicy(p, d, nhead=nhead, nlayers=nlayers, dim_feedforward=width, context_length=seq_len).to(device)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "    seqs = make_seq_dataset(demos, Xn, Yn, seq_len, seq_stride)\n",
    "    for _ in range(epochs):\n",
    "        np.random.shuffle(seqs)\n",
    "        for i in range(0, len(seqs), batch):\n",
    "            bs = seqs[i:i+batch]; maxT = max(s[0].shape[0] for s in bs)\n",
    "            xpad = np.zeros((len(bs), maxT, p), np.float32)\n",
    "            ypad = np.zeros((len(bs), maxT, d), np.float32)\n",
    "            mask = np.zeros((len(bs), maxT), np.float32)\n",
    "            for b, (sx, sy) in enumerate(bs):\n",
    "                T = sx.shape[0]; xpad[b, :T] = sx; ypad[b, :T] = sy; mask[b, :T] = 1.0\n",
    "            xt, yt, mt = to_torch(xpad, ypad, mask, device=device)\n",
    "            pred = net(xt); mse = ((pred - yt)**2).sum(-1)\n",
    "            loss = (mse * mt).sum() / (mt.sum() + 1e-8)\n",
    "            opt.zero_grad(); loss.backward()\n",
    "            if clip: nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "            opt.step()\n",
    "    with torch.no_grad():\n",
    "        total_num = 0.0\n",
    "        total_den = 0.0\n",
    "        for i in range(0, len(seqs), batch):\n",
    "            bs = seqs[i:i+batch]; maxT = max(s[0].shape[0] for s in bs)\n",
    "            xpad = np.zeros((len(bs), maxT, p), np.float32)\n",
    "            ypad = np.zeros((len(bs), maxT, d), np.float32)\n",
    "            mask = np.zeros((len(bs), maxT), np.float32)\n",
    "            for b, (sx, sy) in enumerate(bs):\n",
    "                T = sx.shape[0]; xpad[b, :T] = sx; ypad[b, :T] = sy; mask[b, :T] = 1.0\n",
    "            xt, yt, mt = to_torch(xpad, ypad, mask, device=device)\n",
    "            pred = net(xt); mse = ((pred - yt)**2).sum(-1)\n",
    "            total_num += (mse * mt).sum().item()\n",
    "            total_den += mt.sum().item()\n",
    "        loss = total_num / max(1e-8, total_den)\n",
    "    return net, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_ode(Xn, Yn, epochs=120, lr=1e-3, device=\"cpu\", batch=256, dt=0.1):\n",
    "    p, d = Xn.shape[1], Yn.shape[1]\n",
    "    net = ODEFunc(p, p).to(device)  # ODEFunc maps state to state derivative (p->p)\n",
    "    opt = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    # Convert entire dataset to torch tensors\n",
    "    Xt_full, Yt_full = to_torch(Xn, Yn, device=device)\n",
    "    \n",
    "    # Create time steps for the ODE solver\n",
    "    # This assumes the demo data is uniformly sampled with time step dt\n",
    "    t_span = torch.arange(0, Xt_full.shape[0] * dt, dt).to(device)\n",
    "    \n",
    "    # We will train on batches of full trajectories\n",
    "    unique_demo_ids = np.unique(demo_ids)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        loss_total = 0\n",
    "        for demo_id in unique_demo_ids:\n",
    "            indices = np.where(demo_ids == demo_id)[0]\n",
    "            start_idx = indices[0]\n",
    "            end_idx = indices[-1] + 1\n",
    "            \n",
    "            # Get one full demonstration trajectory\n",
    "            traj_states = Xt_full[start_idx:end_idx]\n",
    "            traj_times = t_span[:len(traj_states)]\n",
    "            \n",
    "            # Solve the ODE from the first state of the trajectory\n",
    "            pred_traj_states = ode.odeint(net, traj_states[0], traj_times)\n",
    "            \n",
    "            # Compute loss between predicted and ground truth trajectories\n",
    "            loss = F.mse_loss(pred_traj_states, traj_states)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            loss_total += loss.item()\n",
    "\n",
    "    # Final training loss\n",
    "    final_loss_total = 0\n",
    "    with torch.no_grad():\n",
    "        for demo_id in unique_demo_ids:\n",
    "            indices = np.where(demo_ids == demo_id)[0]\n",
    "            start_idx = indices[0]\n",
    "            end_idx = indices[-1] + 1\n",
    "            traj_states = Xt_full[start_idx:end_idx]\n",
    "            traj_times = t_span[:len(traj_states)]\n",
    "            \n",
    "            pred_traj_states = ode.odeint(net, traj_states[0], traj_times)\n",
    "            loss = F.mse_loss(pred_traj_states, traj_states)\n",
    "            final_loss_total += loss.item()\n",
    "\n",
    "    return net, final_loss_total / len(unique_demo_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.distributions as D\n",
    "import torchdiffeq as ode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Train & report ----------------\n",
    "p, d = Xn.shape[1], Yn.shape[1]\n",
    "t0 = time.time()\n",
    "bc_net, bc_loss = train_bc(Xn, Yn, epochs=120, device=device)\n",
    "t1 = time.time()\n",
    "traj_net, traj_loss, W_traj = train_traj_bc(demos, Xn, Yn, epochs=120, device=device)\n",
    "t2 = time.time()\n",
    "rnn_net, rnn_loss = train_rnn(demos, Xn, Yn, epochs=120, device=device)\n",
    "t3 = time.time()\n",
    "ileed_net, ileed_loss, ileed_logs = train_ileed_paperfaithful(\n",
    "    demos, Xn, Yn, demo_ids, epochs_warm=60, epochs_joint=90, device=device\n",
    ")\n",
    "t4 = time.time()\n",
    "bc_gaussian_net, bc_gaussian_loss = train_bc_gaussian(Xn, Yn, epochs=120, device=device)\n",
    "t5 = time.time()\n",
    "bc_gmm_net, bc_gmm_loss = train_bc_gmm(Xn, Yn, epochs=120, device=device)\n",
    "t6 = time.time()\n",
    "bc_transformer_net, bc_transformer_loss = train_bc_transformer(demos, Xn, Yn, epochs=120, device=device)\n",
    "t7 = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_net, node_loss = train_neural_ode(Xn, Yn, epochs=2000, device=device)\n",
    "t8 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    {\"model\": \"BC (MLP)\", \"train_objective\": \"Weighted MSE (here: unweighted)\", \"final_loss\": bc_loss, \"time_s\": t1-t0},\n",
    "    {\"model\": \"Traj-BC\", \"train_objective\": \"Weighted MSE (per-trajectory weights)\", \"final_loss\": traj_loss, \"time_s\": t2-t1},\n",
    "    {\"model\": \"BC-RNN (GRU)\", \"train_objective\": \"Masked sequence MSE\", \"final_loss\": rnn_loss, \"time_s\": t3-t2},\n",
    "    {\"model\": \"ILEED (paper-faithful)\", \"train_objective\": \"NLL + aux*lambda + reg\", \"final_loss\": ileed_loss, \"time_s\": t4-t3,\n",
    "     **{f\"ILEED_{k}\": v for k,v in ileed_logs.items()}},\n",
    "    {\"model\": \"BC-Gaussian\", \"train_objective\": \"Negative Log-Likelihood\", \"final_loss\": bc_gaussian_loss, \"time_s\": t5-t4},\n",
    "    {\"model\": \"BC-GMM\", \"train_objective\": \"Negative Log-Likelihood\", \"final_loss\": bc_gmm_loss, \"time_s\": t6-t5},\n",
    "    {\"model\": \"BC-Transformer\", \"train_objective\": \"Masked sequence MSE\", \"final_loss\": bc_transformer_loss, \"time_s\": t7-t6},\n",
    "]\n",
    "\n",
    "# Add the Neural ODE results to the results list\n",
    "results.append({\n",
    "    \"model\": \"Neural ODE\", \n",
    "    \"train_objective\": \"Trajectory MSE\", \n",
    "    \"final_loss\": node_loss, \n",
    "    \"time_s\": t8 - t7\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trajectory generation code starts below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- Updated Rollout Function ----------------\n",
    "def rollout_policy(model, stats, init_state, T=300, model_type=\"bc\", device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Roll out a trajectory from a trained policy.\n",
    "\n",
    "    Args:\n",
    "        model: trained policy (MLP, GRU, or ILEEDGMM)\n",
    "        stats: normalization stats (dict with x_mean, x_std, y_mean, y_std)\n",
    "        init_state: np.array of shape (2,) initial state\n",
    "        T: trajectory length (timesteps)\n",
    "        model_type: one of {\"bc\", \"traj_bc\", \"rnn\", \"ileed\", \"bc_gaussian\", \"bc_gmm\", \"bc_transformer\"}\n",
    "        device: torch device\n",
    "\n",
    "    Returns:\n",
    "        states: np.array (T, 2)\n",
    "        actions: np.array (T, 2)\n",
    "    \"\"\"\n",
    "\n",
    "    x_mean, x_std = stats[\"x_mean\"], stats[\"x_std\"]\n",
    "    y_mean, y_std = stats[\"y_mean\"], stats[\"y_std\"]\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "\n",
    "    # normalize initial state\n",
    "    s = (init_state - x_mean) / x_std\n",
    "    s_torch = torch.tensor(s, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "    # For sequence models (RNN, Transformer)\n",
    "    if model_type in [\"rnn\", \"bc_transformer\"]:\n",
    "        seq_len = 32  # This should match the training seq_len\n",
    "        state_sequence = [s_torch]\n",
    "        if model_type == \"rnn\":\n",
    "            h = None\n",
    "\n",
    "    for t in range(T):\n",
    "        with torch.no_grad():\n",
    "            if model_type in [\"bc\", \"traj_bc\"]:\n",
    "                a_norm = model(s_torch).cpu().numpy()[0]\n",
    "            \n",
    "            elif model_type == \"bc_gaussian\":\n",
    "                dist = model(s_torch)\n",
    "                a_norm = dist.mean.cpu().numpy()[0]\n",
    "            \n",
    "            elif model_type == \"bc_gmm\":\n",
    "                dist = model(s_torch)\n",
    "                a_norm = dist.mean.cpu().numpy()[0]\n",
    "            \n",
    "            elif model_type == \"rnn\":\n",
    "                out, h = model(s_torch.unsqueeze(0), h)\n",
    "                a_norm = out[0, -1].cpu().numpy()\n",
    "            \n",
    "            elif model_type == \"bc_transformer\":\n",
    "                # Get the last `seq_len` states for the context\n",
    "                context_states_list = state_sequence[-seq_len:]\n",
    "                context_states_tensor = torch.stack(context_states_list, dim=1)\n",
    "                \n",
    "                # The transformer expects a batch-first tensor of shape (B, T, p)\n",
    "                out = model(context_states_tensor)\n",
    "                a_norm = out[0, -1].cpu().numpy()\n",
    "\n",
    "            elif model_type == \"ileed\":\n",
    "                pi_logits, mu, sigma = model.gmm_params(s_torch)\n",
    "                rho = torch.ones((1,1), device=device)\n",
    "                logpi = torch.log_softmax(pi_logits, dim=-1)\n",
    "                # pick most likely mixture component\n",
    "                k = torch.argmax(logpi, dim=-1).item()\n",
    "                a_norm = mu[0, k].cpu().numpy()\n",
    "            \n",
    "            # --- New code for Neural ODE model type ---\n",
    "            elif model_type == \"neural_ode\":\n",
    "                # The action is the predicted derivative of the state, s_dot = f(s)\n",
    "                dynamics_func = model\n",
    "                s_dot = dynamics_func(None, s_torch).cpu().numpy()[0]\n",
    "                a_norm = s_dot\n",
    "                \n",
    "            else:\n",
    "                raise ValueError(f\"Unknown model_type {model_type}\")\n",
    "\n",
    "        # unnormalize action\n",
    "        a = a_norm * y_std + y_mean\n",
    "\n",
    "        # store\n",
    "        states.append(s * x_std + x_mean)  # unnormalized\n",
    "        actions.append(a)\n",
    "\n",
    "        # simple dynamics assumption: next state = current state + action * dt\n",
    "        dt = 0.1\n",
    "        s_next = s + (a / x_std) * dt  \n",
    "\n",
    "        # prepare for next step\n",
    "        s = s_next\n",
    "        s_torch = torch.tensor(s, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        \n",
    "        # for sequence models, append the new state to the context\n",
    "        if model_type in [\"rnn\", \"bc_transformer\"]:\n",
    "            state_sequence.append(s_torch)\n",
    "\n",
    "    return np.array(states), np.array(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the display names to the exact model_type strings used in rollout_policy\n",
    "MODEL_TYPE_MAP = {\n",
    "    \"BC\": \"bc\",\n",
    "    \"Traj-BC\": \"traj_bc\",\n",
    "    \"ILEED\": \"ileed\",\n",
    "    \"BC-Gaussian\": \"bc_gaussian\",\n",
    "    \"NeuralODE\": \"neural_ode\"  # Added the Neural ODE model to the map\n",
    "}\n",
    "\n",
    "def perform_multiple_rollouts_and_save(model, stats, T, num_rollouts, display_name, device):\n",
    "    \"\"\"\n",
    "    Performs multiple rollouts for a given model and saves them to an .npy file,\n",
    "    starting from a point with small random variations around a fixed initial state.\n",
    "    \"\"\"\n",
    "    print(f\"Generating {num_rollouts} rollouts for {display_name}...\")\n",
    "    all_trajectories = []\n",
    "    \n",
    "    # Define a fixed starting state (e.g., the first state from the dataset)\n",
    "    base_init_state = X[0]\n",
    "    \n",
    "    # Define the maximum random delta to add to the initial point\n",
    "    delta_max = 0.2\n",
    "    \n",
    "    # Get the correct model_type string from the map\n",
    "    model_type = MODEL_TYPE_MAP.get(display_name)\n",
    "    if not model_type:\n",
    "        raise ValueError(f\"Display name '{display_name}' not found in model type map.\")\n",
    "\n",
    "    for i in range(num_rollouts):\n",
    "        # Add a random delta to the base initial state\n",
    "        random_delta = np.random.uniform(-delta_max, delta_max, size=base_init_state.shape)\n",
    "        init_state = base_init_state + random_delta\n",
    "\n",
    "        states, actions = rollout_policy(model, stats, init_state, T=T, model_type=model_type, device=device)\n",
    "        all_trajectories.append({\"states\": states, \"actions\": actions})\n",
    "\n",
    "    # Dynamically create the file name to prevent overwriting\n",
    "    save_path = f\"{model_type.replace('_', '-')}_rollouts_cleaned.npy\"\n",
    "    np.save(save_path, all_trajectories, allow_pickle=True)\n",
    "    print(f\"Saved {num_rollouts} trajectories to {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "# -------- Run and save multiple rollouts for each model --------\n",
    "num_rollouts_to_generate = 50\n",
    "rollout_horizon = 900\n",
    "\n",
    "saved_files = {}\n",
    "\n",
    "saved_files[\"BC\"] = perform_multiple_rollouts_and_save(bc_net, stats, rollout_horizon, num_rollouts_to_generate, \"BC\", device)\n",
    "saved_files[\"Traj-BC\"] = perform_multiple_rollouts_and_save(traj_net, stats, rollout_horizon, num_rollouts_to_generate, \"Traj-BC\", device)\n",
    "saved_files[\"ILEED\"] = perform_multiple_rollouts_and_save(ileed_net, stats, rollout_horizon, num_rollouts_to_generate, \"ILEED\", device)\n",
    "saved_files[\"NeuralODE\"] = perform_multiple_rollouts_and_save(node_net, stats, rollout_horizon, num_rollouts_to_generate, \"NeuralODE\", device)\n",
    "\n",
    "print(\"\\nAll rollouts saved. The files are:\")\n",
    "for name, path in saved_files.items():\n",
    "    print(f\"- {name}: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define the directory where your .npy files are saved.\n",
    "# REPLACE THIS WITH YOUR ACTUAL PATH.\n",
    "file_directory = \"./\" \n",
    "\n",
    "# Define the models and their corresponding file name bases.\n",
    "# The filenames are derived from the output you provided.\n",
    "models_to_plot_names = [\n",
    "    \"bc_rollouts_cleaned\",\n",
    "    \"traj-bc_rollouts_cleaned\",\n",
    "    \"ileed_rollouts_cleaned\",\n",
    "    \"neural-ode_rollouts_cleaned\"\n",
    "]\n",
    "\n",
    "# Loop through each model name to create and save a separate plot\n",
    "for model_name_base in models_to_plot_names:\n",
    "    # Dynamically construct the file path and name\n",
    "    file_path = os.path.join(file_directory, model_name_base + \".npy\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        # Create a NEW figure for each model inside the loop\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        \n",
    "        # Get the model name for the title and legend label\n",
    "        model_name = model_name_base.replace(\"-rollouts_cleaned\", \"\").replace(\"_\", \" \").replace(\"-\", \" \").upper()\n",
    "\n",
    "        # Set plot parameters for the current figure\n",
    "        plt.xticks(fontsize=16, fontweight=\"bold\")\n",
    "        plt.yticks(fontsize=16, fontweight=\"bold\")\n",
    "        plt.xlim(-2, 2)\n",
    "        plt.ylim(-2, 2)\n",
    "        plt.grid(True, linewidth=1.2)\n",
    "        plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "        # Load the array of dictionaries from the .npy file\n",
    "        all_rollouts = np.load(file_path, allow_pickle=True)\n",
    "        print(f\"Loaded {len(all_rollouts)} rollouts from {file_path}\")\n",
    "\n",
    "        # Generate a colormap with enough colors for all rollouts\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(all_rollouts)))\n",
    "\n",
    "        # Plot all trajectories for the current model\n",
    "        for i, rollout in enumerate(all_rollouts):\n",
    "            states = rollout[\"states\"]\n",
    "            plt.plot(\n",
    "                states[:, 0],\n",
    "                states[:, 1],\n",
    "                alpha=0.8,\n",
    "                linewidth=1.5,\n",
    "                color=colors[i] # Use a unique color from the gradient\n",
    "            )\n",
    "            \n",
    "        # Save the plot with a unique name\n",
    "        output_file = f\"rollout_plot_{model_name.lower().replace(' ', '-')}.png\"\n",
    "        plt.savefig(output_file, dpi=600, bbox_inches=\"tight\")\n",
    "        \n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
