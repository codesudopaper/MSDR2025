{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "mOALqg6mpVVL",
        "outputId": "04b19334-4d84-4383-a6d6-35b4123222e1"
      },
      "outputs": [],
      "source": [
        "# This block of code was taken from:\n",
        "# Farhad Nawaz, Tianyu Li, Nikolai Matni, Nadia Figueroa,\n",
        "# \"Learning Complex Motion Plans using Neural ODEs\n",
        "\n",
        "!pip install gmr\n",
        "import gmr\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.integrate import solve_ivp\n",
        "from scipy import interpolate\n",
        "\n",
        "import jax\n",
        "import jax.nn as jnn\n",
        "import jax.numpy as jnp\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Reading data from text file\n",
        "\n",
        "flag = None\n",
        "traj_all = []\n",
        "traj_c = 0\n",
        "\n",
        "file_name = '/content/trajs_loop_4.txt'\n",
        "\n",
        "f = open(file_name, 'r')\n",
        "data_text = f.readlines()\n",
        "for i in data_text:\n",
        "    if i == 'New trajectory\\n':\n",
        "        flag = 'new'\n",
        "        if traj_c > 0:\n",
        "            traj_all.append(traj)\n",
        "        traj_c += 1\n",
        "        continue\n",
        "    if flag == 'new':\n",
        "        traj = np.fromstring(i, dtype=float, sep=' ').reshape((1, 2))\n",
        "        flag = 'old'\n",
        "        continue\n",
        "    if flag == 'old':\n",
        "        traj = np.concatenate((traj, np.fromstring(i, dtype=float, sep=' ').reshape((1, 2))))\n",
        "traj_all.append(traj)\n",
        "\n",
        "traj_all_norm = []\n",
        "ts_norm = []\n",
        "scaler = MinMaxScaler(feature_range=(-0.5,0.5))\n",
        "scaler_all = []\n",
        "for i in range(len(traj_all)):\n",
        "    scaler.fit(traj_all[i])\n",
        "    scaler_all.append(scaler)\n",
        "    ysti = scaler.transform(traj_all[i])\n",
        "    traj_all_norm.append(ysti)\n",
        "    ts_norm.append(jnp.linspace(0,1,num=ysti.shape[0]))\n",
        "\n",
        "dim = traj.shape[1]\n",
        "\n",
        "nsamples = 300\n",
        "\n",
        "data_aug = 0\n",
        "\n",
        "traj_all_process = jnp.zeros((traj_c + data_aug, nsamples, dim))\n",
        "\n",
        "seed = 1385\n",
        "\n",
        "key = jax.random.PRNGKey(seed)\n",
        "\n",
        "key_trajs = jax.random.split(key, num=traj_c + data_aug)\n",
        "\n",
        "for i in range(traj_c + data_aug):\n",
        "  key_dim = jax.random.split(key_trajs[i], num=dim)\n",
        "  for j in range(dim):\n",
        "    f = interpolate.interp1d(ts_norm[i], traj_all_norm[i][:, j])\n",
        "    ts_new = np.linspace(0, 1, nsamples)\n",
        "    range_traj = max(traj_all_norm[i][:, j]) - min(traj_all_norm[i][:, j])\n",
        "    scale = 0\n",
        "    traj_new = f(ts_new) + jax.random.uniform(key_dim[j], shape=ts_new.shape, minval=-scale*range_traj, maxval=scale*range_traj)\n",
        "    traj_all_process = traj_all_process.at[i, :, j].set(traj_new)\n",
        "\n",
        "traj_d = jnp.diff(traj_all_process, axis=1)\n",
        "traj_d = jnp.concatenate((traj_d, jnp.zeros((traj_c + data_aug, 1, dim))), axis=1)\n",
        "traj_d_all = jnp.concatenate((traj_all_process, traj_d), axis=2)\n",
        "\n",
        "for i in range(traj_c + data_aug):\n",
        "    plt.plot(traj_all_process[i][0, 0], traj_all_process[i][0, 1], 'ro')\n",
        "    plt.plot(traj_all_process[i][:, 0], traj_all_process[i][:, 1])\n",
        "    plt.plot(traj_all_process[i][-1, 0], traj_all_process[i][-1, 1], 'go')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "QXRgrs52AWAr",
        "outputId": "939f45e9-9af8-4e6e-9cab-f2eb5637a47f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# generate parameter\n",
        "t = np.linspace(0, 2*np.pi, 300)\n",
        "\n",
        "# lemniscate of Gerono (figure-eight)\n",
        "x = np.sin(t)\n",
        "y = np.sin(t) * np.cos(t)\n",
        "\n",
        "# rescale to [-0.5, 0.5]\n",
        "x = 0.5 * x\n",
        "y = 0.5 * y\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(x, y, label=\"Figure-8 Trajectory\")\n",
        "plt.plot(x[0], y[0], \"ro\", label=\"Start\")\n",
        "plt.plot(x[-1], y[-1], \"go\", label=\"End\")\n",
        "plt.xlim([-0.5, 0.5])\n",
        "plt.ylim([-0.5, 0.5])\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.legend()\n",
        "plt.title(\"Horizontal 8-shaped trajectory\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "U56FZro7Uxi7",
        "outputId": "6e2c742d-f6c9-4be1-8e81-0eee93e897b7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "n_points = 300\n",
        "x_max = 1.0\n",
        "y_max = 0.25  # reduce vertical amplitude to decrease area\n",
        "theta = np.pi / 4  # 45 degrees rotation\n",
        "\n",
        "# Forward path (pick) - unsymmetric\n",
        "t_up = np.linspace(0, 1, n_points//2)\n",
        "x_up = x_max * t_up\n",
        "y_up = y_max * np.sin(np.pi * t_up) * (1 + 0.2 * t_up)  # smaller deviation\n",
        "\n",
        "# Backward path (place) - unsymmetric\n",
        "t_down = np.linspace(0, 1, n_points//2)\n",
        "x_down = x_max * (1 - t_down)\n",
        "y_down = -y_max * np.sin(np.pi * t_down) * (1 + 0.1 * t_down**2)  # smaller deviation\n",
        "\n",
        "# Concatenate\n",
        "x = np.concatenate([x_up, x_down])\n",
        "y = np.concatenate([y_up, y_down])\n",
        "\n",
        "# Rotation matrix for 45 degrees\n",
        "R = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "              [np.sin(theta),  np.cos(theta)]])\n",
        "\n",
        "coords = np.stack([x, y], axis=0)\n",
        "rotated_coords = R @ coords\n",
        "x_rot, y_rot = rotated_coords[0, :], rotated_coords[1, :]\n",
        "\n",
        "# Stack into (n_points, 2)\n",
        "bh_like_traj_rot = np.column_stack((x_rot, y_rot))\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(x_rot, y_rot, label=\"Rotated Unsymmetric Pick-and-Place Loop\")\n",
        "plt.plot(x_rot[0], y_rot[0], \"ro\", label=\"Start\")\n",
        "plt.plot(x_rot[-1], y_rot[-1], \"go\", label=\"End\")\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.title(\"Closed Rotated Unsymmetric Pick-and-Place Trajectory (Reduced Area)\")\n",
        "plt.gca().set_aspect('equal', adjustable='box')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GzClmMtAgBJ",
        "outputId": "749e9f69-969d-48db-acef-b13265931917"
      },
      "outputs": [],
      "source": [
        "traj = np.column_stack((x, y))\n",
        "traj.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15D4755JVJ9h"
      },
      "outputs": [],
      "source": [
        "bh_like_traj_rot.shape\n",
        "traj = bh_like_traj_rot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "9MhxvXL7i7a2",
        "outputId": "2c4e943f-aeff-48d7-a724-8554b65c05d7"
      },
      "outputs": [],
      "source": [
        "from scipy.interpolate import interp1d\n",
        "#drawing = np.array(traj_all_process[0, :, :])\n",
        "drawing = traj\n",
        "\n",
        "def normalize_drawing(d):\n",
        "    d = d - np.mean(d, axis=0)\n",
        "    max_range = np.max(np.abs(d))\n",
        "    return d / max_range\n",
        "\n",
        "def rotate_and_scale_drawing(d, angle_degrees=0.0, scale_x=1.0, scale_y=1.0):\n",
        "    theta = np.radians(angle_degrees)\n",
        "    rotation_matrix = np.array([\n",
        "        [np.cos(theta), -np.sin(theta)],\n",
        "        [np.sin(theta),  np.cos(theta)]\n",
        "    ])\n",
        "    scaling_matrix = np.diag([scale_x, scale_y])\n",
        "    transform = rotation_matrix @ scaling_matrix\n",
        "    return d @ transform.T\n",
        "\n",
        "def add_noise(drawing, noise_scale=0.13):\n",
        "    return drawing + np.random.normal(scale=noise_scale, size=drawing.shape)\n",
        "\n",
        "def simplify_and_interpolate(drawing, keep_ratio=0.05, noise_scale=0.2):\n",
        "    num_points = int(len(drawing) * keep_ratio)\n",
        "    idx = np.sort(np.random.choice(len(drawing), num_points, replace=False))\n",
        "    simplified = drawing[idx]\n",
        "    simplified += np.random.normal(scale=noise_scale, size=simplified.shape)\n",
        "    f_interp = interp1d(np.linspace(0, 1, num_points), simplified, axis=0, kind='cubic')\n",
        "    return f_interp(np.linspace(0, 1, len(drawing)))\n",
        "\n",
        "def distort_shape(drawing):\n",
        "    scales = np.random.uniform(0.9, 1, size=(len(drawing), 2))\n",
        "    return drawing * scales\n",
        "\n",
        "def exaggerate_parts(drawing, start=100, end=250, factor=1.3):\n",
        "    modified = drawing.copy()\n",
        "    modified[start:end] *= factor\n",
        "    return modified\n",
        "\n",
        "def create_childlike_versions(drawing):\n",
        "    drawing = normalize_drawing(drawing)\n",
        "\n",
        "    version1 = add_noise(drawing)\n",
        "    version2 = simplify_and_interpolate(drawing)\n",
        "    version3 = distort_shape(drawing)\n",
        "    version4 = exaggerate_parts(drawing)\n",
        "\n",
        "    version1 = (rotate_and_scale_drawing(version1,5,1,1))\n",
        "    version2 = (rotate_and_scale_drawing(version2,-5,1.1,1.1))\n",
        "    version3 = (rotate_and_scale_drawing(version3,10,1.2,1.2))\n",
        "    version4 = (rotate_and_scale_drawing(version4,-10,1.3,1.3))\n",
        "\n",
        "    return version1, version2, version3, version4\n",
        "\n",
        "\n",
        "drawing = normalize_drawing(drawing)\n",
        "child1, child2, child3, child4 = create_childlike_versions(drawing)\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 5, figsize=(22, 4))\n",
        "titles = ['Expert (Original)', 'Child 1: Noisy', 'Child 2: Simplified',\n",
        "          'Child 3: Distorted', 'Child 4: Exaggerated']\n",
        "\n",
        "for ax, data, title in zip(axs, [drawing, child1, child2, child3, child4], titles):\n",
        "    ax.plot(data[:, 0], data[:, 1], lw=2)\n",
        "    ax.set_title(title)\n",
        "    ax.axis('equal')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UgrLv-Vq2O5"
      },
      "outputs": [],
      "source": [
        "noisy_d = np.array([child1, child2, child3, child4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "o4u_QYcdwJs1",
        "outputId": "b661946a-6d41-4f79-dea2-a3f36c5b9e2a"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "for i in range(4):\n",
        "    x = noisy_d[i, :, 0]\n",
        "    y = noisy_d[i, :, 1]\n",
        "\n",
        "    ax = axes[i]\n",
        "    ax.plot(x, y, lw=2)\n",
        "    ax.set_title(f\"Trajectory {i+1}\")\n",
        "    ax.set_xlabel(\"X\")\n",
        "    ax.set_ylabel(\"Y\")\n",
        "    ax.set_aspect('equal')\n",
        "    ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxdyasuxpzh3",
        "outputId": "543baceb-cb3a-48a2-ffdb-885242a0403b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.special import digamma\n",
        "\n",
        "def compute_mi_knn(x, y, k=5):\n",
        "    \"\"\"\n",
        "    Compute mutual information between x and y using KSG estimator (K nearest neighbors).\n",
        "    x, y: arrays of shape (N, d_x) and (N, d_y)\n",
        "    k: number of neighbors\n",
        "    \"\"\"\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    n = x.shape[0]\n",
        "\n",
        "    data = np.hstack((x, y))\n",
        "    tree = NearestNeighbors(metric='chebyshev')\n",
        "    tree.fit(data)\n",
        "    dist, _ = tree.kneighbors(data, n_neighbors=k+1)  # include itself\n",
        "    eps = dist[:, k]  # distance to k-th neighbor\n",
        "\n",
        "    # Count neighbors in marginal spaces\n",
        "    tree_x = NearestNeighbors(metric='chebyshev')\n",
        "    tree_x.fit(x)\n",
        "    nx = tree_x.radius_neighbors(x, radius=eps - 1e-15, return_distance=False)\n",
        "    nx = np.array([len(neigh) - 1 for neigh in nx])  # exclude itself\n",
        "\n",
        "    tree_y = NearestNeighbors(metric='chebyshev')\n",
        "    tree_y.fit(y)\n",
        "    ny = tree_y.radius_neighbors(y, radius=eps - 1e-15, return_distance=False)\n",
        "    ny = np.array([len(neigh) - 1 for neigh in ny])\n",
        "\n",
        "    mi = digamma(k) + digamma(n) - np.mean(digamma(nx + 1) + digamma(ny + 1))\n",
        "    return mi\n",
        "\n",
        "# Example data: 4 trajectories, 300 steps, 2D states\n",
        "np.random.seed(0)\n",
        "states = noisy_d\n",
        "\n",
        "n_traj, T, state_dim = states.shape\n",
        "\n",
        "def compute_traj_mi_score(traj, k=5):\n",
        "    \"\"\"\n",
        "    For one trajectory, compute total mutual information score between\n",
        "    states and actions (actions = diff of states).\n",
        "    \"\"\"\n",
        "    actions = np.diff(traj, axis=0)  # shape (T-1, state_dim)\n",
        "    states_trim = traj[:-1]          # align states (T-1, state_dim)\n",
        "    # Compute MI between states_trim and actions (both shape (T-1, state_dim))\n",
        "    mi_score = compute_mi_knn(states_trim, actions, k)\n",
        "    return mi_score * (T - 1)  # sum MI over all pairs (approximate total)\n",
        "\n",
        "# Compute MI scores for all trajectories\n",
        "scores = []\n",
        "for i in range(n_traj):\n",
        "    score = compute_traj_mi_score(states[i])\n",
        "    print(f\"Trajectory {i} MI score: {score:.4f}\")\n",
        "    scores.append(score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVi8Sbpw0IPj",
        "outputId": "f7790a43-bad0-4b20-e465-c2202e116f0f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.special import digamma\n",
        "\n",
        "# ---- Your existing loss functions ----\n",
        "\n",
        "def smoothness_losst(pred):\n",
        "    dx = torch.diff(pred[:, 0], dim=0)\n",
        "    dy = torch.diff(pred[:, 1], dim=0)\n",
        "    return torch.sum(dx**2 + dy**2).item()\n",
        "\n",
        "def closed_shape_loss(pred):\n",
        "    return torch.norm(pred[0] - pred[-1], dim=-1).item()\n",
        "\n",
        "def symmetry_loss(pred):\n",
        "    centroid = torch.mean(pred, dim=0)\n",
        "    reflected_x = 2 * centroid[0] - pred[:, 0]\n",
        "    reflected_points = torch.stack((reflected_x, pred[:, 1]), dim=1)\n",
        "    diff = reflected_points.unsqueeze(1) - pred.unsqueeze(0)\n",
        "    dists = torch.norm(diff, dim=2)\n",
        "    min_dists, _ = torch.min(dists, dim=1)\n",
        "    return torch.mean(min_dists).item()\n",
        "\n",
        "def compute_scores(pred):\n",
        "    return {\n",
        "        'Smoothness': smoothness_losst(pred),\n",
        "        'Closed Shape': closed_shape_loss(pred),\n",
        "        'Symmetry': symmetry_loss(pred)\n",
        "    }\n",
        "\n",
        "# ---- Mutual Information estimator using sklearn KNN ----\n",
        "\n",
        "def compute_mi_knn(x, y, k=5):\n",
        "    \"\"\"\n",
        "    Compute mutual information between x and y using KSG estimator (K nearest neighbors).\n",
        "    x, y: arrays of shape (N, d_x) and (N, d_y)\n",
        "    \"\"\"\n",
        "    n = x.shape[0]\n",
        "    data = np.hstack((x, y))\n",
        "    tree = NearestNeighbors(metric='chebyshev')\n",
        "    tree.fit(data)\n",
        "    dist, _ = tree.kneighbors(data, n_neighbors=k+1)\n",
        "    eps = dist[:, k] - 1e-15  # distance to kth neighbor, small epsilon\n",
        "\n",
        "    tree_x = NearestNeighbors(metric='chebyshev').fit(x)\n",
        "    nx = np.array([len(tree_x.radius_neighbors([point], radius=eps[i], return_distance=False)[0]) - 1 for i, point in enumerate(x)])\n",
        "\n",
        "    tree_y = NearestNeighbors(metric='chebyshev').fit(y)\n",
        "    ny = np.array([len(tree_y.radius_neighbors([point], radius=eps[i], return_distance=False)[0]) - 1 for i, point in enumerate(y)])\n",
        "\n",
        "    from scipy.special import digamma\n",
        "    mi = digamma(k) + digamma(n) - np.mean(digamma(nx + 1) + digamma(ny + 1))\n",
        "    return mi\n",
        "\n",
        "def compute_mi_score_torch(pred, k=5):\n",
        "    \"\"\"\n",
        "    pred: torch tensor (T, 2) states\n",
        "    Compute MI between states and actions (diff of states)\n",
        "    \"\"\"\n",
        "    states = pred[:-1].cpu().numpy()      # (T-1, 2)\n",
        "    actions = (pred[1:] - pred[:-1]).cpu().numpy()  # (T-1, 2)\n",
        "    return compute_mi_knn(states, actions, k)\n",
        "\n",
        "# ---- Your input tensors ----\n",
        "# assuming drawing, child1, child2, child3, child4 are defined as numpy arrays\n",
        "drawing = torch.tensor(drawing, dtype=torch.float32)\n",
        "chil1 = torch.tensor(child1, dtype=torch.float32)\n",
        "chil2 = torch.tensor(child2, dtype=torch.float32)\n",
        "chil3 = torch.tensor(child3, dtype=torch.float32)\n",
        "chil4 = torch.tensor(child4, dtype=torch.float32)\n",
        "\n",
        "drawings = [drawing, chil1, chil2, chil3, chil4]\n",
        "\n",
        "# Compute existing losses\n",
        "score_dicts = [compute_scores(d) for d in drawings]\n",
        "\n",
        "# Compute MI scores for each trajectory\n",
        "mi_scores = [compute_mi_score_torch(d) for d in drawings]\n",
        "\n",
        "# Combine all metrics to normalize (including MI)\n",
        "weights = {\n",
        "    'Symmetry': 1.0,\n",
        "    'Closed Shape': 0.5,\n",
        "    'Smoothness': 0.1,\n",
        "    'Mutual Information': 1.0  # weight for MI (used only in weighted sum later)\n",
        "}\n",
        "\n",
        "# Extract metrics from score_dicts and add MI\n",
        "all_metrics = {key: [d[key] for d in score_dicts] for key in weights if key != 'Mutual Information'}\n",
        "all_metrics['Mutual Information'] = mi_scores\n",
        "\n",
        "# Normalize scores between 0 and 1 per metric\n",
        "def normalize_list(vals):\n",
        "    arr = np.array(vals)\n",
        "    min_val, max_val = arr.min(), arr.max()\n",
        "    if max_val - min_val < 1e-8:\n",
        "        return [0.0 for _ in vals]\n",
        "    return ((arr - min_val) / (max_val - min_val)).tolist()\n",
        "\n",
        "normalized_scores = []\n",
        "for i in range(len(drawings)):\n",
        "    norm_score = {}\n",
        "    for k in all_metrics:\n",
        "        norm_vals = normalize_list(all_metrics[k])\n",
        "        norm_score[k] = norm_vals[i]\n",
        "    normalized_scores.append(norm_score)\n",
        "\n",
        "# Now compute final scores as (1-beta)*MI - beta*(weighted sum of other losses)\n",
        "beta = 0.5  # tune this parameter [0,1]\n",
        "\n",
        "final_scores = []\n",
        "for norm_score in normalized_scores:\n",
        "    weighted_loss = sum(norm_score[k] * weights[k] for k in weights if k != 'Mutual Information')\n",
        "    combined = (1 - beta) * norm_score['Mutual Information'] - beta * weighted_loss\n",
        "    final_scores.append(combined)\n",
        "\n",
        "# Normalize final scores between 0 and 1 for interpretability\n",
        "final_scores_np = np.array(final_scores)\n",
        "min_fs, max_fs = final_scores_np.min(), final_scores_np.max()\n",
        "if max_fs - min_fs < 1e-8:\n",
        "    final_scores_norm = [0.0 for _ in final_scores]\n",
        "else:\n",
        "    final_scores_norm = ((final_scores_np - min_fs) / (max_fs - min_fs)).tolist()\n",
        "\n",
        "# Titles with scores\n",
        "titles_with_scores = [\n",
        "    f'Original Expert | Final Score: {final_scores_norm[0]:.3f}',\n",
        "    f'Child 1: Noisy | Final Score: {final_scores_norm[1]:.3f}',\n",
        "    f'Child 2: Simplified | Final Score: {final_scores_norm[2]:.3f}',\n",
        "    f'Child 3: Distorted | Final Score: {final_scores_norm[3]:.3f}',\n",
        "    f'Child 4: Exaggerated | Final Score: {final_scores_norm[4]:.3f}'\n",
        "]\n",
        "\n",
        "for title in titles_with_scores:\n",
        "    print(title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "CRFlZIqg0LMy",
        "outputId": "1dcbb4a3-f570-496f-e8a1-aaa2e47d2e68"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(1, 5, figsize=(22, 5))\n",
        "\n",
        "for ax, data, title, score, mi in zip(axs, drawings, titles_with_scores, score_dicts, mi_scores):\n",
        "    data_np = data.numpy()\n",
        "    ax.plot(data_np[:, 0], data_np[:, 1], lw=2)\n",
        "    ax.axis('equal')\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Combine existing losses and add Mutual Information\n",
        "    score_with_mi = score.copy()\n",
        "    score_with_mi['Mutual Information'] = mi\n",
        "\n",
        "    score_text = '\\n'.join([f\"{k}: {v:.3f}\" for k, v in score_with_mi.items()])\n",
        "    ax.text(0.05, 0.95, score_text, transform=ax.transAxes, fontsize=12,\n",
        "            verticalalignment='top', bbox=dict(facecolor='white', alpha=0.7, edgecolor='none'))\n",
        "    ax.set_title(title, fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKzEV4ax1b2W"
      },
      "outputs": [],
      "source": [
        "class PeriodicDMP:\n",
        "    def __init__(self, n_dof=2, n_basis=20, tau=1.0, alpha=25.0, beta=10.0):\n",
        "        self.n_dof = n_dof\n",
        "        self.n_basis = n_basis\n",
        "        self.tau = tau\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "        self.time = np.linspace(0, tau, 300)\n",
        "        self.psi = self._compute_basis_functions(self.time)\n",
        "\n",
        "        self.weights = np.random.randn(self.n_basis, self.n_dof)\n",
        "\n",
        "    def _compute_basis_functions(self, time):\n",
        "\n",
        "        centers = np.linspace(0, 1, self.n_basis)\n",
        "        psi = np.exp(-self.alpha * (time[:, None] - centers[None, :]) ** 2)\n",
        "        return psi\n",
        "\n",
        "    def fit(self, trajectory):\n",
        "        goal_position = trajectory[-1]\n",
        "\n",
        "        for i in range(self.n_dof):\n",
        "            self.weights[:, i] = np.linalg.lstsq(self.psi, trajectory[:, i], rcond=None)[0]\n",
        "\n",
        "    def generate(self, goal_position):\n",
        "        y = np.zeros((len(self.time), self.n_dof))\n",
        "        dy = np.zeros((len(self.time), self.n_dof))\n",
        "\n",
        "        for i in range(len(self.time)):\n",
        "            for j in range(self.n_dof):\n",
        "                y[i, j] = np.dot(self.psi[i, :], self.weights[:, j])\n",
        "\n",
        "            dy[i] = np.gradient(y[i], self.time[i])\n",
        "\n",
        "        return y, dy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "LmrrThY_1IzE",
        "outputId": "cf6e947d-132a-4121-c486-4d713107571d"
      },
      "outputs": [],
      "source": [
        "example_trajectory = child1\n",
        "dmp = PeriodicDMP(n_dof=2)\n",
        "\n",
        "dmp.fit(example_trajectory)\n",
        "\n",
        "goal_position = example_trajectory[-1]\n",
        "\n",
        "target_trajectory, _ = dmp.generate(goal_position)\n",
        "\n",
        "plt.plot(target_trajectory[:, 0], target_trajectory[:, 1], label='Generated by DMP', color='r')\n",
        "plt.plot(example_trajectory[:, 0], example_trajectory[:, 1], label='Original Trajectory', color='b', linestyle='dashed')\n",
        "plt.title(\"Original vs. Generated Trajectory\")\n",
        "plt.legend()\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWxV2V-t4AYY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden_size=128, output_size=2, num_layers=2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, (hn, cn) = self.lstm(x)\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n",
        "\n",
        "def smoothness_loss(pred):\n",
        "\n",
        "    dx = torch.diff(pred[:, :, 0], dim=0)\n",
        "    dy = torch.diff(pred[:, :, 1], dim=0)\n",
        "    d1 = dx**2 + dy**2\n",
        "    loss_d1 = torch.sum(d1)\n",
        "\n",
        "    ddx = torch.diff(dx, dim=0)\n",
        "    ddy = torch.diff(dy, dim=0)\n",
        "    d2 = ddx**2 + ddy**2\n",
        "    loss_d2 = torch.sum(d2)\n",
        "\n",
        "    dddx = torch.diff(ddx, dim=0)\n",
        "    dddy = torch.diff(ddy, dim=0)\n",
        "    d3 = dddx**2 + dddy**2\n",
        "    loss_d3 = torch.sum(d3)\n",
        "\n",
        "    loss = 0.2 * loss_d1 + 0.3 * loss_d2 + 0.5 * loss_d3\n",
        "\n",
        "    return loss\n",
        "\n",
        "def closed_shape_loss(pred):\n",
        "    return torch.norm(pred[:,:,0] - pred[:,:,-1])\n",
        "\n",
        "def symmetry_loss(pred):\n",
        "    pred = pred.squeeze(0)\n",
        "\n",
        "    centroid = torch.mean(pred, dim=0)\n",
        "\n",
        "    reflected_x = 2 * centroid[0] - pred[:, 0]\n",
        "    reflected_points = torch.stack((reflected_x, pred[:, 1]), dim=1)\n",
        "\n",
        "    diff = reflected_points[:, None, :] - pred[None, :, :]\n",
        "    dists = torch.norm(diff, dim=2)  # [T, T]\n",
        "\n",
        "    min_dists, _ = torch.min(dists, dim=1)\n",
        "\n",
        "    return torch.mean(min_dists)\n",
        "\n",
        "\n",
        "def shape_preservation_loss(pred, dmp_trajectory, weight_edge=12):\n",
        "    dmp_tensor = torch.tensor(dmp_trajectory, dtype=pred.dtype, device=pred.device)\n",
        "\n",
        "    diffs = torch.norm(pred - dmp_tensor, dim=-1)\n",
        "\n",
        "\n",
        "    weights = 1*torch.ones_like(diffs)\n",
        "    weights[0] = weight_edge\n",
        "    weights[-1] = weight_edge\n",
        "\n",
        "\n",
        "    loss = torch.sum(weights * diffs)\n",
        "    return loss\n",
        "\n",
        "model = LSTMModel(input_size=2, hidden_size=128, output_size=2, num_layers=2)\n",
        "\n",
        "mse_loss_function = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbk20DRqxMtv",
        "outputId": "320631ff-61df-4034-9785-b1f37e255f6a"
      },
      "outputs": [],
      "source": [
        "expert_trajectory = np.array(target_trajectory)\n",
        "\n",
        "target1 = rotate_and_scale_drawing(expert_trajectory, angle_degrees=0, scale_x=1, scale_y=1)\n",
        "target2 = rotate_and_scale_drawing(expert_trajectory, angle_degrees=-10, scale_x=1.1, scale_y=1.1)\n",
        "target3 = rotate_and_scale_drawing(expert_trajectory, angle_degrees=5, scale_x=1.2, scale_y=1.2)\n",
        "target4 = rotate_and_scale_drawing(expert_trajectory, angle_degrees=-15, scale_x=1.3, scale_y=1.3)\n",
        "\n",
        "target_shapes = [target1, target2, target3, target4]\n",
        "\n",
        "child_drawings_np = np.stack([child1, child2, child3, child4])\n",
        "inputs = torch.tensor(child_drawings_np, dtype=torch.float32)\n",
        "targets = inputs.clone()\n",
        "\n",
        "target_shapes_torch = [torch.tensor(t, dtype=torch.float32) for t in target_shapes]\n",
        "\n",
        "model = LSTMModel(input_size=2, hidden_size=128, output_size=2, num_layers=2)\n",
        "mse_loss_function = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_epoch_loss = 0.0\n",
        "\n",
        "    for i in range(inputs.shape[0]):\n",
        "        input_i = inputs[i].unsqueeze(0)\n",
        "        target_i = targets[i].unsqueeze(0)\n",
        "        target_shape_i = target_shapes_torch[i]\n",
        "\n",
        "        output_i = model(input_i)\n",
        "\n",
        "        mse_loss = mse_loss_function(output_i, target_i)\n",
        "        sm_loss = smoothness_loss(output_i)\n",
        "        cs_loss = closed_shape_loss(output_i)\n",
        "        sy_loss = symmetry_loss(output_i)\n",
        "        shape_loss = shape_preservation_loss(output_i.squeeze(0), target_shape_i)\n",
        "\n",
        "        total_loss = 0.9*mse_loss + 0.1 * sm_loss + 0.1 * cs_loss + 0.1 * sy_loss + 0.1 * shape_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_epoch_loss += total_loss.item()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        avg_loss = total_epoch_loss / inputs.shape[0]\n",
        "        print(f\"Epoch [{epoch}/{epochs}], Avg Loss per Trajectory: {avg_loss:.4f}\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    cleaned_drawings = model(inputs)  # (4, 300, 2)\n",
        "    cleaned_drawings_np = cleaned_drawings.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt-tEhSswO4l",
        "outputId": "19e6f2eb-e722-4a8e-b01e-9c7a354be312"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from scipy.special import digamma\n",
        "\n",
        "# Your existing LSTM model and losses unchanged\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=2, hidden_size=128, output_size=2, num_layers=2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, (hn, cn) = self.lstm(x)\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n",
        "\n",
        "def smoothness_loss(pred):\n",
        "    dx = torch.diff(pred[:, :, 0], dim=0)\n",
        "    dy = torch.diff(pred[:, :, 1], dim=0)\n",
        "    d1 = dx**2 + dy**2\n",
        "    loss_d1 = torch.sum(d1)\n",
        "\n",
        "    ddx = torch.diff(dx, dim=0)\n",
        "    ddy = torch.diff(dy, dim=0)\n",
        "    d2 = ddx**2 + ddy**2\n",
        "    loss_d2 = torch.sum(d2)\n",
        "\n",
        "    dddx = torch.diff(ddx, dim=0)\n",
        "    dddy = torch.diff(ddy, dim=0)\n",
        "    d3 = dddx**2 + dddy**2\n",
        "    loss_d3 = torch.sum(d3)\n",
        "\n",
        "    loss = 0.2 * loss_d1 + 0.3 * loss_d2 + 0.5 * loss_d3\n",
        "    return loss\n",
        "\n",
        "def closed_shape_loss(pred):\n",
        "    return torch.norm(pred[:,:,0] - pred[:,:,-1])\n",
        "\n",
        "def symmetry_loss(pred):\n",
        "    pred = pred.squeeze(0)\n",
        "    centroid = torch.mean(pred, dim=0)\n",
        "    reflected_x = 2 * centroid[0] - pred[:, 0]\n",
        "    reflected_points = torch.stack((reflected_x, pred[:, 1]), dim=1)\n",
        "    diff = reflected_points[:, None, :] - pred[None, :, :]\n",
        "    dists = torch.norm(diff, dim=2)\n",
        "    min_dists, _ = torch.min(dists, dim=1)\n",
        "    return torch.mean(min_dists)\n",
        "\n",
        "def shape_preservation_loss(pred, dmp_trajectory, weight_edge=12):\n",
        "    # If dmp_trajectory is a numpy array:\n",
        "    if isinstance(dmp_trajectory, torch.Tensor):\n",
        "        dmp_tensor = dmp_trajectory.detach().clone().to(dtype=pred.dtype, device=pred.device)\n",
        "    else:\n",
        "        dmp_tensor = torch.tensor(dmp_trajectory, dtype=pred.dtype, device=pred.device)\n",
        "\n",
        "    diffs = torch.norm(pred - dmp_tensor, dim=-1)\n",
        "\n",
        "    weights = torch.ones_like(diffs)\n",
        "    weights[0] = weight_edge\n",
        "    weights[-1] = weight_edge\n",
        "\n",
        "    loss = torch.sum(weights * diffs)\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Mutual Information using KNN-based estimator (scikit-learn + numpy)\n",
        "def compute_mi_knn(x, y, k=5):\n",
        "    n = x.shape[0]\n",
        "    data = np.hstack((x, y))\n",
        "    tree = NearestNeighbors(metric='chebyshev').fit(data)\n",
        "    dist, _ = tree.kneighbors(data, n_neighbors=k+1)\n",
        "    eps = dist[:, k] - 1e-15\n",
        "\n",
        "    tree_x = NearestNeighbors(metric='chebyshev').fit(x)\n",
        "    nx = np.array([len(tree_x.radius_neighbors([point], radius=eps[i], return_distance=False)[0]) - 1 for i, point in enumerate(x)])\n",
        "\n",
        "    tree_y = NearestNeighbors(metric='chebyshev').fit(y)\n",
        "    ny = np.array([len(tree_y.radius_neighbors([point], radius=eps[i], return_distance=False)[0]) - 1 for i, point in enumerate(y)])\n",
        "\n",
        "    mi = digamma(k) + digamma(n) - np.mean(digamma(nx + 1) + digamma(ny + 1))\n",
        "    return mi\n",
        "\n",
        "def compute_mi_score_torch(pred, k=5):\n",
        "    states = pred[:-1].detach().cpu().numpy()\n",
        "    actions = (pred[1:] - pred[:-1]).detach().cpu().numpy()\n",
        "    return compute_mi_knn(states, actions, k)\n",
        "\n",
        "\n",
        "# --- State visitation rate & reward calculation ---\n",
        "def compute_state_visitation_rate(trajectories, grid_size=50):\n",
        "    \"\"\"\n",
        "    trajectories: list of numpy arrays of shape (T, 2)\n",
        "    grid_size: number of bins per axis for discretizing state space\n",
        "    Returns:\n",
        "      visitation_map: 2D np.array normalized visitation counts\n",
        "      states_grids: list of (T, 2) tuples of grid indices for each trajectory's states\n",
        "    \"\"\"\n",
        "    # Collect all points for global grid bounds\n",
        "    all_points = np.vstack(trajectories)\n",
        "    x_min, y_min = all_points.min(axis=0)\n",
        "    x_max, y_max = all_points.max(axis=0)\n",
        "\n",
        "    # Create bins\n",
        "    x_bins = np.linspace(x_min, x_max, grid_size + 1)\n",
        "    y_bins = np.linspace(y_min, y_max, grid_size + 1)\n",
        "\n",
        "    visitation_map = np.zeros((grid_size, grid_size))\n",
        "\n",
        "    states_grids = []\n",
        "    for traj in trajectories:\n",
        "        x_idx = np.digitize(traj[:, 0], bins=x_bins) - 1\n",
        "        y_idx = np.digitize(traj[:, 1], bins=y_bins) - 1\n",
        "        x_idx = np.clip(x_idx, 0, grid_size - 1)\n",
        "        y_idx = np.clip(y_idx, 0, grid_size - 1)\n",
        "        states_grids.append(np.stack([x_idx, y_idx], axis=1))\n",
        "        for xi, yi in zip(x_idx, y_idx):\n",
        "            visitation_map[yi, xi] += 1  # note: y is row, x is col\n",
        "\n",
        "    visitation_map /= visitation_map.sum()  # Normalize to sum=1 (probability)\n",
        "    return visitation_map, states_grids\n",
        "\n",
        "def compute_trajectory_reward(states_grid, visitation_map):\n",
        "    \"\"\"\n",
        "    states_grid: (T,2) numpy array of grid indices for a trajectory\n",
        "    visitation_map: (grid_size, grid_size) visitation probabilities\n",
        "    Reward is sum of visitation probabilities of the visited states normalized by length.\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "    for (y_idx, x_idx) in states_grid:  # Note: visitation_map is (row=y, col=x)\n",
        "        rewards.append(visitation_map[y_idx, x_idx])\n",
        "    return np.sum(rewards) / len(rewards)\n",
        "\n",
        "# --- Your training setup ---\n",
        "expert_trajectory = np.array(target_trajectory)\n",
        "\n",
        "target1 = rotate_and_scale_drawing(expert_trajectory, angle_degrees=0, scale_x=1, scale_y=1)\n",
        "target2 = rotate_and_scale_drawing(expert_trajectory, angle_degrees=-10, scale_x=1.1, scale_y=1.1)\n",
        "target3 = rotate_and_scale_drawing(expert_trajectory, angle_degrees=5, scale_x=1.2, scale_y=1.2)\n",
        "target4 = rotate_and_scale_drawing(expert_trajectory, angle_degrees=-15, scale_x=1.3, scale_y=1.3)\n",
        "\n",
        "target_shapes = [target1, target2, target3, target4]\n",
        "\n",
        "child_drawings_np = np.stack([child1, child2, child3, child4])\n",
        "inputs = torch.tensor(child_drawings_np, dtype=torch.float32)\n",
        "targets = inputs.clone()\n",
        "target_shapes_torch = [torch.tensor(t, dtype=torch.float32) for t in target_shapes]\n",
        "\n",
        "model = LSTMModel(input_size=2, hidden_size=128, output_size=2, num_layers=2)\n",
        "mse_loss_function = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Beta initialization\n",
        "beta = 0.5\n",
        "policy_rewards_history = []\n",
        "\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_epoch_loss = 0.0\n",
        "    epoch_policy_rewards = []\n",
        "\n",
        "    for i in range(inputs.shape[0]):\n",
        "        input_i = inputs[i].unsqueeze(0)\n",
        "        target_i = targets[i].unsqueeze(0)\n",
        "        target_shape_i = target_shapes_torch[i]\n",
        "\n",
        "        output_i = model(input_i)\n",
        "\n",
        "        # Compute MI score on output\n",
        "        mi_score = compute_mi_score_torch(output_i.squeeze(0))\n",
        "\n",
        "        # Compute losses\n",
        "        mse_loss = mse_loss_function(output_i, target_i)\n",
        "        sm_loss = smoothness_loss(output_i)\n",
        "        cs_loss = closed_shape_loss(output_i)\n",
        "        sy_loss = symmetry_loss(output_i)\n",
        "        shape_loss = shape_preservation_loss(output_i.squeeze(0), target_shape_i)\n",
        "\n",
        "        # Weighted sum of other losses (excluding MI)\n",
        "        weighted_loss = 0.9 * mse_loss + 0.1 * sm_loss + 0.1 * cs_loss + 0.1 * sy_loss + 0.1 * shape_loss\n",
        "\n",
        "        # Total loss with beta weighting\n",
        "        total_loss = (1 - beta) * (-mi_score) + beta * weighted_loss\n",
        "        # Note: We negate mi_score to maximize MI (since optimizer minimizes)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_epoch_loss += total_loss.item()\n",
        "\n",
        "        # Save trajectory output to compute visitation later\n",
        "        epoch_policy_rewards.append(output_i.squeeze(0).cpu().detach().numpy())\n",
        "\n",
        "    # Compute visitation map and reward for this epoch's trajectories\n",
        "    visitation_map, states_grids = compute_state_visitation_rate(epoch_policy_rewards)\n",
        "    rewards = [compute_trajectory_reward(sg, visitation_map) for sg in states_grids]\n",
        "    mean_reward = np.mean(rewards)\n",
        "    policy_rewards_history.append(mean_reward)\n",
        "\n",
        "    # Update beta (if not first epoch)\n",
        "    if epoch > 0:\n",
        "        prev_reward = policy_rewards_history[-2]\n",
        "        delta_reward = mean_reward - prev_reward\n",
        "\n",
        "        # # If reward increased, increase beta -> more weight on losses, less on MI\n",
        "        # # If reward decreased, decrease beta -> more weight on MI\n",
        "        # beta += 0.1 * delta_reward\n",
        "        beta += 0.1 * np.tanh(10 * delta_reward)\n",
        "\n",
        "        beta = max(0.0, min(1.0, beta))  # clip beta between 0 and 1\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch [{epoch}/{epochs}], Avg Loss: {total_epoch_loss / inputs.shape[0]:.4f}, Beta: {beta:.3f}, Mean Reward: {mean_reward:.4f}\")\n",
        "\n",
        "# Final evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    cleaned_drawings = model(inputs)\n",
        "    cleaned_drawings_np = cleaned_drawings.numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "q0800gyBx77S",
        "outputId": "d1919f0e-a417-47a4-c946-96b7d90918f6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "child_titles = ['Teacher 1', 'Teacher 2', 'Teacher 3', 'Teacher 4']\n",
        "cleaned_titles = ['Cleaned 1', 'Cleaned 2', 'Cleaned 3', 'Cleaned 4']\n",
        "\n",
        "target_trajectories = [target1, target2, target3, target4]\n",
        "\n",
        "all_x = np.concatenate([child[:, 0] for child in [child1, child2, child3, child4]] +\n",
        "                       [target[:, 0] for target in target_trajectories])\n",
        "all_y = np.concatenate([child[:, 1] for child in [child1, child2, child3, child4]] +\n",
        "                       [target[:, 1] for target in target_trajectories])\n",
        "\n",
        "x_min, x_max = all_x.min(), all_x.max()\n",
        "y_min, y_max = all_y.min(), all_y.max()\n",
        "\n",
        "x_margin = 0.1 * (x_max - x_min)\n",
        "y_margin = 0.1 * (y_max - y_min)\n",
        "\n",
        "x_limits = (x_min - x_margin, x_max + x_margin)\n",
        "y_limits = (y_min - y_margin, y_max + y_margin)\n",
        "\n",
        "fig, axs = plt.subplots(1, 4, figsize=(18, 4))\n",
        "for ax, child, target, title in zip(axs, [child1, child2, child3, child4], target_trajectories, child_titles):\n",
        "    ax.plot(target[:, 0], target[:, 1], color='red', lw=3, linestyle='--', label='Target Trajectory')\n",
        "    ax.plot(child[:, 0], child[:, 1], lw=2, label='Child Drawing')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    ax.set_xlim(x_limits)\n",
        "    ax.set_ylim(y_limits)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    ax.tick_params(axis='both', which='both', length=5, labelsize=8)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.legend()\n",
        "\n",
        "fig, axs = plt.subplots(1, 4, figsize=(18, 4))\n",
        "for ax, cleaned, target, title in zip(axs, cleaned_drawings_np, target_trajectories, cleaned_titles):\n",
        "    ax.plot(target[:, 0], target[:, 1], color='red', lw=3, linestyle='--', label='Target Trajectory')\n",
        "    ax.plot(cleaned[:, 0], cleaned[:, 1], lw=2, color='blue', label='Cleaned Drawing')\n",
        "    ax.set_title(title)\n",
        "\n",
        "    ax.set_xlim(x_limits)\n",
        "    ax.set_ylim(y_limits)\n",
        "    ax.set_aspect('equal')\n",
        "\n",
        "    ax.tick_params(axis='both', which='both', length=5, labelsize=8)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "jme2QzvTA_ig",
        "outputId": "0deb1e99-f72a-45b4-886e-2be56360752d"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "x = np.linspace(0, 4 * np.pi, 300)\n",
        "y = np.sin(x)\n",
        "trajectory = drawing\n",
        "\n",
        "indices_uniform = np.linspace(0, 299, 60, dtype=int)\n",
        "trajectory_uniform = trajectory[indices_uniform]\n",
        "\n",
        "trajectory_avg = trajectory.reshape(60, 5, 2).mean(axis=1)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(trajectory[:, 0], trajectory[:, 1], label='Original', color='gray')\n",
        "plt.title('Original (300 points)')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(trajectory[:, 0], trajectory[:, 1], color='gray', alpha=0.3)\n",
        "plt.plot(2*trajectory_uniform[:, 0], 2*trajectory_uniform[:, 1], 'o-', label='Uniform Sampled', color='blue')\n",
        "plt.title('Uniform Sampling (60 points)')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(trajectory[:, 0], trajectory[:, 1], color='gray', alpha=0.3)\n",
        "plt.plot(2*trajectory_avg[:, 0], 2*trajectory_avg[:, 1], 'o-', label='Block Averaged', color='green')\n",
        "plt.title('Block Averaging (60 points)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piFFfHSt0XWO",
        "outputId": "8fc36cb9-c137-4af7-b593-7ce53209852c"
      },
      "outputs": [],
      "source": [
        "noisy_d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htgn7Y_UCaHG"
      },
      "outputs": [],
      "source": [
        "T = 6.0\n",
        "ts_new = np.linspace(0, T, 60)\n",
        "dt = ts_new[1] - ts_new[0]\n",
        "\n",
        "vel_standard = np.gradient(noisy_d, dt, axis=1)\n",
        "\n",
        "traj_standard = np.concatenate([noisy_d, vel_standard], axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HadArbZ3A7Va"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "curr_path = os.getcwd()\n",
        "save_dir = os.path.join(curr_path, 'config', 'Data_Trajs')\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "data_file = os.path.join(save_dir, 'noisy_dataset.npy')\n",
        "with open(data_file, 'wb') as f:\n",
        "    np.save(f, traj_standard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-lnnHaBOtnx",
        "outputId": "97b9a1a5-7ed3-4413-8424-9f56ffb8c207"
      },
      "outputs": [],
      "source": [
        "trajectory_uniform.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUWQXSpWOlSD"
      },
      "outputs": [],
      "source": [
        "data_file = os.path.join(save_dir, 'draw_ref.npy')\n",
        "with open(data_file, 'wb') as f:\n",
        "    np.save(f, 2*trajectory_uniform)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
